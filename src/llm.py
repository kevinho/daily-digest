import os
import re
from typing import Dict, List, Optional

from dotenv import load_dotenv

# Ensure .env is loaded even when llm is imported standalone; tolerate permission issues
try:
    load_dotenv()
except PermissionError:
    pass


def _get_openai_client():
    """Get OpenAI client if available, None otherwise."""
    api_key = os.getenv("OPENAI_API_KEY")
    # Clean any proxy envs that might be injected by shell/tools
    for k in [
        "OPENAI_PROXY",
        "OPENAI_HTTP_PROXY",
        "OPENAI_HTTPS_PROXY",
        "HTTP_PROXY",
        "HTTPS_PROXY",
        "ALL_PROXY",
        "http_proxy",
        "https_proxy",
        "all_proxy",
    ]:
        os.environ.pop(k, None)

    try:
        import openai  # type: ignore

        openai.proxy = None
        openai.proxies = None
        from openai import OpenAI as _OpenAI  # type: ignore

        class OpenAI(_OpenAI):  # type: ignore
            def __init__(self, *args, **kwargs):
                kwargs.pop("proxies", None)
                kwargs.pop("proxy", None)
                super().__init__(*args, **kwargs)

    except ImportError:
        return None

    if not api_key:
        return None
    
    return OpenAI(api_key=api_key)


def generate_overview(items: List[Dict]) -> str:
    """
    Generate a comprehensive overview for a batch of items (100-150 chars).
    
    Args:
        items: List of items, each with title, summary/tldr, tags
        
    Returns:
        Overview text (100-150 Chinese characters)
    """
    if not items:
        return "æœ¬æ‰¹æ¬¡æ— å†…å®¹ã€‚"
    
    client = _get_openai_client()
    if client:
        try:
            # Build content summary for prompt
            content_lines = []
            for item in items[:20]:  # Limit to 20 items
                tags = item.get("tags", ["æœªåˆ†ç±»"])
                tag = tags[0] if tags else "æœªåˆ†ç±»"
                title = item.get("title", "æ— æ ‡é¢˜")
                summary = (item.get("summary") or item.get("tldr") or "")[:100]
                content_lines.append(f"- [{tag}] {title}: {summary}")
            
            content_summary = "\n".join(content_lines)
            
            prompt = f"""è¯·ä¸ºä»¥ä¸‹{len(items)}æ¡å†…å®¹ç”Ÿæˆä¸€æ®µç»¼åˆæ¦‚è¿°ï¼ˆ100-150å­—ï¼‰ã€‚
è¦æ±‚ï¼š
1. æ¦‚æ‹¬ä¸»è¦ä¸»é¢˜ç±»åˆ«å’Œæ•°é‡åˆ†å¸ƒ
2. æç‚¼æ ¸å¿ƒè¦ç‚¹å’Œäº®ç‚¹
3. ä½¿ç”¨ä¸­æ–‡ï¼Œç®€æ´æ˜Žäº†

å†…å®¹åˆ—è¡¨ï¼š
{content_summary}

è¯·ç›´æŽ¥è¾“å‡ºæ¦‚è¿°å†…å®¹ï¼Œä¸è¦æ·»åŠ æ ‡é¢˜æˆ–å‰ç¼€ã€‚"""

            resp = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.3,
            )
            content = resp.choices[0].message.content or ""
            return content.strip()
        except Exception as e:
            print(f"OpenAI error in generate_overview: {e}")
    
    # Fallback to simple overview
    return generate_overview_fallback(items)


def generate_overview_fallback(items: List[Dict]) -> str:
    """
    Generate a simple overview without AI.
    
    Args:
        items: List of items
        
    Returns:
        Simple overview text
    """
    if not items:
        return "æœ¬æ‰¹æ¬¡æ— å†…å®¹ã€‚"
    
    # Count by tag
    tag_counts: Dict[str, int] = {}
    for item in items:
        tags = item.get("tags", ["æœªåˆ†ç±»"])
        for tag in tags:
            tag_counts[tag] = tag_counts.get(tag, 0) + 1
    
    # Build overview
    total = len(items)
    tag_parts = []
    for tag, count in sorted(tag_counts.items(), key=lambda x: -x[1]):
        tag_parts.append(f"{tag}ï¼ˆ{count}æ¡ï¼‰")
    
    tags_str = "ã€".join(tag_parts[:5])  # Top 5 tags
    
    # Get first few titles as highlights
    highlights = []
    for item in items[:3]:
        title = item.get("title", "")
        if title:
            highlights.append(title[:20])
    
    highlights_str = "ã€".join(highlights) if highlights else ""
    
    overview = f"æœ¬æ‰¹æ¬¡å…±æ”¶é›†{total}æ¡å†…å®¹ï¼Œæ¶µç›–{tags_str}ã€‚"
    if highlights_str:
        overview += f"é‡ç‚¹å†…å®¹åŒ…æ‹¬ï¼š{highlights_str}ç­‰ã€‚"
    
    return overview[:200]  # Limit length


def categorize_items(items: List[Dict]) -> Dict[str, List[int]]:
    """
    Use AI to categorize items into meaningful groups.
    
    Args:
        items: List of items with title, summary/tldr
        
    Returns:
        Dict mapping category name to list of item indices
    """
    if not items:
        return {}
    
    client = _get_openai_client()
    if not client:
        return _categorize_fallback(items)
    
    try:
        # Build item descriptions for prompt
        item_lines = []
        for i, item in enumerate(items[:30]):  # Limit to 30 items
            title = item.get("title", "æ— æ ‡é¢˜")[:50]
            summary = (item.get("summary") or item.get("tldr") or "")[:80]
            # Clean summary
            summary = re.sub(r'\*{0,2}TLDR:?\*{0,2}\s*', '', summary, flags=re.IGNORECASE)
            summary = summary.split('\n')[0][:80]
            item_lines.append(f"{i}. {title} - {summary}")
        
        items_text = "\n".join(item_lines)
        
        prompt = f"""è¯·å°†ä»¥ä¸‹{len(items)}æ¡å†…å®¹åˆ†ç±»åˆ°3-6ä¸ªæœ‰æ„ä¹‰çš„ç±»åˆ«ä¸­ã€‚

è¦æ±‚ï¼š
1. ç±»åˆ«åç§°è¦ç®€æ´ï¼ˆ2-4ä¸ªå­—ï¼‰ï¼Œå¦‚"AIæ•™è‚²"ã€"å¼€æºå·¥å…·"ã€"æŠ•èµ„ç†è´¢"
2. æ¯ä¸ªå†…å®¹åªåˆ†åˆ°ä¸€ä¸ªæœ€ç›¸å…³çš„ç±»åˆ«
3. è¿”å›žJSONæ ¼å¼ï¼š{{"ç±»åˆ«å": [åºå·åˆ—è¡¨], ...}}

å†…å®¹åˆ—è¡¨ï¼š
{items_text}

è¯·ç›´æŽ¥è¿”å›žJSONï¼Œä¸è¦æ·»åŠ å…¶ä»–å†…å®¹ã€‚"""

        resp = client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
            messages=[{"role": "user", "content": prompt}],
            max_tokens=500,
            temperature=0.3,
        )
        content = resp.choices[0].message.content or "{}"
        
        # Parse JSON response
        import json
        # Clean up potential markdown code blocks
        content = re.sub(r'```json\s*', '', content)
        content = re.sub(r'```\s*', '', content)
        content = content.strip()
        
        result = json.loads(content)
        return result
        
    except Exception as e:
        print(f"AI categorization error: {e}")
        return _categorize_fallback(items)


def _categorize_fallback(items: List[Dict]) -> Dict[str, List[int]]:
    """Fallback categorization by content_type/item_type."""
    categories: Dict[str, List[int]] = {}
    
    for i, item in enumerate(items):
        content_type = (item.get("content_type") or "").upper()
        item_type = (item.get("item_type") or "").upper()
        
        if content_type and content_type not in ("HTML", "UNKNOWN", ""):
            cat = f"ðŸ“„ {content_type}"
        elif item_type == "NOTE_CONTENT":
            cat = "ðŸ“ ç¬”è®°"
        else:
            cat = "ðŸ”— ç½‘é¡µ"
        
        if cat not in categories:
            categories[cat] = []
        categories[cat].append(i)
    
    return categories


def parse_highlights(insights: str) -> List[str]:
    """
    Parse insights text into a list of highlights.
    
    Args:
        insights: Raw insights text (may contain bullet points)
        
    Returns:
        List of highlight strings (3-5 items, each â‰¤30 chars)
    """
    if not insights:
        return []
    
    # Split by newlines and clean up
    lines = insights.strip().split("\n")
    highlights = []
    
    for line in lines:
        # Remove bullet markers
        line = line.strip()
        line = re.sub(r"^[-â€¢*Â·]\s*", "", line)
        line = re.sub(r"^\d+[.ã€]\s*", "", line)  # Remove numbered list markers
        line = line.strip()
        
        if not line:
            continue
        
        # Remove common prefixes like "Insights:" or "è¦ç‚¹:"
        line = re.sub(r"^(Insights|è¦ç‚¹|TLDR|æ€»ç»“)[ï¼š:]\s*", "", line, flags=re.IGNORECASE)
        line = line.strip()
        
        if not line:
            continue
        
        # Truncate to 30 chars if needed
        if len(line) > 30:
            line = line[:30]
        
        highlights.append(line)
        
        if len(highlights) >= 5:
            break
    
    return highlights[:5]  # Max 5 highlights


def generate_digest(text: str) -> Dict[str, str]:
    """
    Summarize text with OpenAI if available; otherwise fall back to truncate.
    """
    client = _get_openai_client()
    
    if client:
        try:
            prompt = (
                "è¯·ç”¨ä¸­æ–‡æ€»ç»“ä¸‹é¢å†…å®¹ï¼Œè¾“å‡ºä¸¤éƒ¨åˆ†ï¼š\n"
                "TLDR: ä¸€å¥è¯æ€»ç»“\n"
                "Insights: åˆ—å‡º3-5æ¡è¦ç‚¹ï¼Œæ¯æ¡ä¸è¶…è¿‡30å­—ã€‚\n\n"
                f"å†…å®¹:\n{text[:8000]}"
            )
            resp = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.3,
            )
            content = resp.choices[0].message.content or ""
            # ç®€å•åˆ‡åˆ†ï¼šç¬¬ä¸€è¡Œ TLDRï¼Œå…¶ä½™ä¸º insights
            lines = [ln.strip() for ln in content.splitlines() if ln.strip()]
            tldr = lines[0] if lines else content[:200]
            insights = "\n".join(lines[1:]) if len(lines) > 1 else "- " + tldr
            return {"tldr": tldr, "insights": insights}
        except Exception as e:
            print(f"OpenAI error: {e}")
    
    # Fallback
    tldr = (text or "TL;DR placeholder")[:120]
    # Try to create simple bullet insights from sentences
    sentences = re.split(r"[ã€‚ï¼ï¼Ÿ!?\.]\s*", text or "")
    insights_list = []
    for s in sentences:
        s = s.strip()
        if s:
            insights_list.append(f"- {s[:80]}")
        if len(insights_list) >= 3:
            break
    insights = "\n".join(insights_list) if insights_list else "- " + tldr
    return {
        "tldr": tldr,
        "insights": insights,
    }


def classify(text: str) -> Dict[str, any]:
    """Stub classifier; replace with rule+LLM hybrid."""
    return {
        "tags": ["general"],
        "sensitivity": "public",
        "confidence": 0.8,
        "rule_version": "rule-v0",
        "prompt_version": "prompt-v0",
    }


def summarize_sections(items: List[Dict[str, str]]) -> List[Dict[str, str]]:
    """
    Produce lightweight section summaries with citations.
    Each item should have: id, title, summary (tldr), tags.
    """
    sections: List[Dict[str, str]] = []
    for item in items:
        title = item.get("title") or item.get("id", "item")
        tldr = item.get("summary") or item.get("tldr") or ""
        sections.append(
            {
                "title": title,
                "summary": tldr[:500],
                "citations": [item.get("id")],
                "tags": item.get("tags", []),
            }
        )
    return sections


# ============================================================
# Digest Generation Functions for Reporting System
# ============================================================

def generate_daily_digest(items: List[Dict]) -> Dict[str, any]:
    """
    Generate a daily digest from inbox items.
    
    Args:
        items: List of items with title, summary, tags
        
    Returns:
        Dict with 'overview', 'highlights', 'categories'
    """
    if not items:
        return {
            "overview": "ä»Šæ—¥æ— æ–°å¢žå†…å®¹ã€‚",
            "highlights": [],
            "categories": {},
        }
    
    client = _get_openai_client()
    if client:
        try:
            # Build content summary
            content_lines = []
            for item in items[:30]:  # Limit items
                title = item.get("title", "æ— æ ‡é¢˜")
                tags = item.get("tags", ["æœªåˆ†ç±»"])
                summary = (item.get("summary") or "")[:100]
                content_lines.append(f"- [{', '.join(tags[:2])}] {title}: {summary}")
            
            content_summary = "\n".join(content_lines)
            
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†ç®¡ç†åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä»Šæ—¥æ”¶é›†çš„{len(items)}æ¡å†…å®¹æ‘˜è¦ï¼Œç”Ÿæˆä¸€ä»½"ä»Šæ—¥çŸ¥è¯†åœ°å›¾"ï¼š

{content_summary}

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼ˆä¸è¦æ·»åŠ ```jsonæ ‡è®°ï¼‰ï¼š
{{
    "overview": "ä»Šæ—¥çŸ¥è¯†æ”¶èŽ·æ€»ç»“ï¼ˆ100-150å­—ï¼‰",
    "highlights": ["é‡ç‚¹å†…å®¹1", "é‡ç‚¹å†…å®¹2", "é‡ç‚¹å†…å®¹3"],
    "hot_topics": ["çƒ­é—¨è¯é¢˜1", "çƒ­é—¨è¯é¢˜2"]
}}"""

            resp = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500,
                temperature=0.3,
            )
            content = resp.choices[0].message.content or "{}"
            # Clean up markdown formatting if present
            content = content.strip()
            if content.startswith("```"):
                content = re.sub(r"^```\w*\n?", "", content)
                content = re.sub(r"\n?```$", "", content)
            
            import json
            result = json.loads(content)
            return {
                "overview": result.get("overview", ""),
                "highlights": result.get("highlights", []),
                "categories": {},
            }
        except Exception as e:
            print(f"OpenAI error in generate_daily_digest: {e}")
    
    # Fallback
    return _daily_digest_fallback(items)


def _daily_digest_fallback(items: List[Dict]) -> Dict[str, any]:
    """Fallback daily digest without AI."""
    # Count tags
    tag_counts: Dict[str, int] = {}
    for item in items:
        for tag in item.get("tags", ["æœªåˆ†ç±»"]):
            tag_counts[tag] = tag_counts.get(tag, 0) + 1
    
    # Build overview
    total = len(items)
    top_tags = sorted(tag_counts.items(), key=lambda x: -x[1])[:5]
    tag_str = "ã€".join(f"{t}ï¼ˆ{c}æ¡ï¼‰" for t, c in top_tags)
    overview = f"ä»Šæ—¥å…±æ”¶é›†{total}æ¡å†…å®¹ï¼Œæ¶µç›–{tag_str}ã€‚"
    
    # Extract highlights (top 3-5 titles)
    highlights = [item.get("title", "")[:30] for item in items[:5] if item.get("title")]
    
    return {
        "overview": overview,
        "highlights": highlights,
        "categories": {},
    }


def generate_weekly_digest(daily_reports: List[Dict]) -> Dict[str, any]:
    """
    Generate a weekly digest from daily reports.
    
    Args:
        daily_reports: List of daily report dicts with overview, highlights
        
    Returns:
        Dict with 'overview', 'trends', 'emerging', 'fading'
    """
    if not daily_reports:
        return {
            "overview": "æœ¬å‘¨æ— æ—¥æŠ¥è®°å½•ã€‚",
            "trends": [],
            "emerging": [],
            "fading": [],
        }
    
    client = _get_openai_client()
    if client:
        try:
            # Build daily summaries
            daily_lines = []
            for report in daily_reports:
                date_str = report.get("date", "")
                overview = report.get("summary") or report.get("overview", "")
                highlights = report.get("highlights", [])
                highlights_str = "ã€".join(highlights[:3]) if highlights else ""
                daily_lines.append(f"- {date_str}: {overview[:100]} è¦ç‚¹ï¼š{highlights_str}")
            
            daily_summary = "\n".join(daily_lines)
            
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†ç®¡ç†åŠ©æ‰‹ã€‚è¯·æ ¹æ®è¿‡åŽ»ä¸€å‘¨çš„{len(daily_reports)}å¤©æ—¥æŠ¥æ€»ç»“ï¼Œç”Ÿæˆå‘¨åº¦çŸ¥è¯†æŠ¥å‘Šï¼š

{daily_summary}

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼ˆä¸è¦æ·»åŠ ```jsonæ ‡è®°ï¼‰ï¼š
{{
    "overview": "æœ¬å‘¨çŸ¥è¯†è¶‹åŠ¿æ€»ç»“ï¼ˆ150-200å­—ï¼‰",
    "trends": ["çƒ­é—¨è¯é¢˜1", "çƒ­é—¨è¯é¢˜2", "çƒ­é—¨è¯é¢˜3"],
    "emerging": ["æ–°å…´è¯é¢˜1"],
    "fading": ["æ¶ˆå¤±è¯é¢˜1"]
}}"""

            resp = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500,
                temperature=0.3,
            )
            content = resp.choices[0].message.content or "{}"
            content = content.strip()
            if content.startswith("```"):
                content = re.sub(r"^```\w*\n?", "", content)
                content = re.sub(r"\n?```$", "", content)
            
            import json
            result = json.loads(content)
            return {
                "overview": result.get("overview", ""),
                "trends": result.get("trends", []),
                "emerging": result.get("emerging", []),
                "fading": result.get("fading", []),
            }
        except Exception as e:
            print(f"OpenAI error in generate_weekly_digest: {e}")
    
    # Fallback
    return _weekly_digest_fallback(daily_reports)


def _weekly_digest_fallback(daily_reports: List[Dict]) -> Dict[str, any]:
    """Fallback weekly digest without AI."""
    count = len(daily_reports)
    
    # Aggregate all highlights
    all_highlights = []
    for report in daily_reports:
        all_highlights.extend(report.get("highlights", []))
    
    overview = f"æœ¬å‘¨å…±{count}å¤©æœ‰å†…å®¹è®°å½•ã€‚"
    
    return {
        "overview": overview,
        "trends": all_highlights[:5],
        "emerging": [],
        "fading": [],
    }


def generate_monthly_digest(weekly_reports: List[Dict]) -> Dict[str, any]:
    """
    Generate a monthly digest from weekly reports.
    
    Args:
        weekly_reports: List of weekly report dicts
        
    Returns:
        Dict with 'overview', 'dominant_themes', 'evolution'
    """
    if not weekly_reports:
        return {
            "overview": "æœ¬æœˆæ— å‘¨æŠ¥è®°å½•ã€‚",
            "dominant_themes": [],
            "evolution": "",
        }
    
    client = _get_openai_client()
    if client:
        try:
            # Build weekly summaries
            weekly_lines = []
            for report in weekly_reports:
                title = report.get("title", "")
                overview = report.get("summary") or report.get("overview", "")
                trends = report.get("highlights", [])
                trends_str = "ã€".join(trends[:3]) if trends else ""
                weekly_lines.append(f"- {title}: {overview[:100]} è¶‹åŠ¿ï¼š{trends_str}")
            
            weekly_summary = "\n".join(weekly_lines)
            
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†ç®¡ç†åŠ©æ‰‹ã€‚è¯·æ ¹æ®æœ¬æœˆçš„{len(weekly_reports)}ä¸ªå‘¨æŠ¥æ€»ç»“ï¼Œç”Ÿæˆæœˆåº¦çŸ¥è¯†å›žé¡¾ï¼š

{weekly_summary}

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼ˆä¸è¦æ·»åŠ ```jsonæ ‡è®°ï¼‰ï¼š
{{
    "overview": "æœ¬æœˆçŸ¥è¯†èŽ·å–é«˜å±‚æ¬¡æ€»ç»“ï¼ˆ200-250å­—ï¼‰",
    "dominant_themes": ["ä¸»å¯¼ä¸»é¢˜1", "ä¸»å¯¼ä¸»é¢˜2"],
    "evolution": "è¯é¢˜æ¼”å˜æè¿°ï¼ˆä»Žæœˆåˆåˆ°æœˆæœ«çš„å˜åŒ–ï¼‰"
}}"""

            resp = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                messages=[{"role": "user", "content": prompt}],
                max_tokens=600,
                temperature=0.3,
            )
            content = resp.choices[0].message.content or "{}"
            content = content.strip()
            if content.startswith("```"):
                content = re.sub(r"^```\w*\n?", "", content)
                content = re.sub(r"\n?```$", "", content)
            
            import json
            result = json.loads(content)
            return {
                "overview": result.get("overview", ""),
                "dominant_themes": result.get("dominant_themes", []),
                "evolution": result.get("evolution", ""),
            }
        except Exception as e:
            print(f"OpenAI error in generate_monthly_digest: {e}")
    
    # Fallback
    return _monthly_digest_fallback(weekly_reports)


def _monthly_digest_fallback(weekly_reports: List[Dict]) -> Dict[str, any]:
    """Fallback monthly digest without AI."""
    count = len(weekly_reports)
    
    # Aggregate themes
    all_themes = []
    for report in weekly_reports:
        all_themes.extend(report.get("highlights", []))
    
    overview = f"æœ¬æœˆå…±{count}å‘¨æœ‰å†…å®¹è®°å½•ã€‚"
    
    return {
        "overview": overview,
        "dominant_themes": all_themes[:5],
        "evolution": "",
    }
